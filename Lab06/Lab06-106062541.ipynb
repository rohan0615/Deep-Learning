{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452 rows and 281 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>arrhythmia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1    2   3    4    5    6    7    8   9     ...       271  272  273  \\\n",
       "0  75  0  190  80   91  193  371  174  121 -16     ...       9.0 -0.9  0.0   \n",
       "1  56  1  165  64   81  174  401  149   39  25     ...       8.5  0.0  0.0   \n",
       "2  54  0  172  95  138  163  386  185  102  96     ...       9.5 -2.4  0.0   \n",
       "3  55  0  175  94  100  202  380  179  143  28     ...      12.2 -2.2  0.0   \n",
       "4  75  0  190  80   88  181  360  177  103 -16     ...      13.1 -3.6  0.0   \n",
       "\n",
       "   274  275  276   277   278  279  arrhythmia  \n",
       "0  0.0  0.9  2.9  23.3  49.4    8           1  \n",
       "1  0.0  0.2  2.1  20.4  38.8    6           1  \n",
       "2  0.0  0.3  3.4  12.3  49.0   10           1  \n",
       "3  0.0  0.4  2.6  34.6  61.6    1           0  \n",
       "4  0.0 -0.1  3.9  25.4  62.8    7           1  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading of dataset.\n",
    "data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/arrhythmia/arrhythmia.data', header=None, sep=',', engine='python')\n",
    "data['arrhythmia'] = data[len(data.columns)-1].map(lambda x: 0 if x==1 else 1)\n",
    "print('%d rows and %d columns' % (data.shape[0],data.shape[1]))\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 452 rows and 274 columns\n",
      "y:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "    # retain the columns with numeric values.\n",
    "data_num = data._get_numeric_data()\n",
    "X = data_num.iloc[:, :-2]  # The first to third-last columns are the features\n",
    "y = data_num.iloc[:, -1]   # The last column is the ground-truth label\n",
    "print('X: %d rows and %d columns' % (X.shape[0], X.shape[1]))\n",
    "print('y: ', np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Training Data: 316\n",
      "#Testing Data: 136\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset to training and validation datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20171012)\n",
    "print('#Training Data: %d' % X_train.shape[0])\n",
    "print('#Testing Data: %d' % X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardizing the training and test datasets\n",
    "# Note that we are scaling based on the information from the training data\n",
    "# Then we apply the scaling that is done from training data to the test data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Building of a Logistic Regression model using scikit-learn with random_state = 0.\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_std)\n",
    "\n",
    "#AUC\n",
    "probas = lr.predict_proba(X_test_std)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,\n",
    "                                 probas[:, 0],\n",
    "                                 pos_label=0)\n",
    "print('AUC: %.2f' % auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.80\n",
      "C: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Building of a regularized Logistic Regression model with random_state = 0. Tune the C parameter until AUC >= 0.79.\n",
    "weights, params, auc_list = [], [], []\n",
    "for c in np.arange(-10, 10, 0.1):\n",
    "    lr = LogisticRegression(C=10**c, random_state=0)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    \n",
    "    probas = lr.predict_proba(X_test_std)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,\n",
    "                                 probas[:, 0],\n",
    "                                 pos_label=0)\n",
    "    auc_list.append(auc(fpr, tpr))\n",
    "    # get the coefficients of w\n",
    "    weights.append(lr.coef_[0])\n",
    "    params.append(10**c)\n",
    "Best_C = params[auc_list.index(max(auc_list))]\n",
    "print('AUC: %.2f' % max(auc_list))\n",
    "print('C: %.2f' % Best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import interp\n",
    "from cycler import cycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAEYCAYAAACHjumMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b3804062e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting of the confusion matrix and the ROC curve of the best regularized Logistic Regression model.\n",
    "lr = LogisticRegression(C=Best_C, random_state=0)\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_std)\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "        \n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 從我的 Confusion Matrix 可以發現：這次實驗的 Logistic Regression 整體的正確率是 $\\frac{(63+36)}{(63+36+7+30)}\\approx 0.73$，而錯誤率則是 $\\frac{(7+30)}{(63+36+7+30)}\\approx 0.27$。  \n",
    "2. 其中，從我 predict 錯誤的 data 可以發現：$PRE=\\frac{63}{63+30}\\approx 0.68$，也就是說我 predict 是 $0$ 的 data 中，有大約三分之一是我誤將 $1$ predict 成 $0$ 的情況；不過根據 $REC=\\frac{63}{63+7}=0.9 $，我能將九成的 ground truth 是 $0$ 的 labels 正確判斷出來。\n",
    "從以上能得出，我的 $F_1=2\\times \\frac{PRE\\times REC}{PRE+REC}\\approx 0.78$  \n",
    "3. 此外，由我 FP 和 FN 可以發現，我大部分的錯誤都集中在 FP ，也就是將 $1$ 誤認為 $0$ 的情況，代表我的 model 在這個判斷上有些問題。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAHwCAYAAABZrD3mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b3fe743518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "\n",
    "probas = lr.predict_proba(X_test_std)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test,\n",
    "                                 probas[:, 0],\n",
    "                                 pos_label=0)\n",
    "plt.plot(fpr, tpr, lw=2,\n",
    "         label='Logistic regression')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=4, prop={'size': 18})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一個完美的 ROC 會是由左下到左上的一條垂直線，轉折成一個左上到右上的水平線；而一個亂猜的 ROC 則是一條對角線。  \n",
    "從我的圖來觀察，可以看到我的圖形基本上比較接近前者，也就是比較好的 ROC。  \n",
    "此外，根據 AUC 的結果，由於我的 AUC = 0.8，因此我的圖形應該要接近比較好的 ROC；實際觀察圖形後也確實如此。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save Image\n",
    "lr = LogisticRegression(C=Best_C, random_state=0)\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_std)\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(7,7))\n",
    "ax1.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax1.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "\n",
    "probas = lr.predict_proba(X_test_std)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test,\n",
    "                                 probas[:, 0],\n",
    "                                 pos_label=0)\n",
    "plt.plot(fpr, tpr, lw=2,\n",
    "         label='Logistic regression')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=4, prop={'size': 10})\n",
    "plt.savefig('Lab6-106062541', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
